"""
==============================================================================
NBA ORACLE — Azure ML Prediction Post-Processor
==============================================================================
Subject: Cloud Computing (Defense: February 19, 2026)
Purpose: Takes raw Azure ML prediction CSV outputs and transforms them into
         a structured JSON file for the NBA Oracle web dashboard.

CORE CONCEPTS EXPLAINED:
-------------------------
1. NORMALIZATION (Min-Max Scaling)
   - Raw stats (like Offensive Rating = 120.0) are on different scales.
   - Min-Max Scaling converts ALL stats to a 0–100 scale so we can compare
     them fairly and combine them into one "overall rating."
   
   Formula:  normalized = ((value - min) / (max - min)) × 100
   
   Example:  If Off Ratings range from 110 to 121 across all teams:
             - A team with 121 → ((121 - 110) / (121 - 110)) × 100 = 100 (best)
             - A team with 110 → ((110 - 110) / (121 - 110)) × 100 = 0   (worst)
             - A team with 115 → ((115 - 110) / (121 - 110)) × 100 = 45.5 (mid)

2. DEFENSIVE RATING INVERSION
   - Defensive Rating = points ALLOWED per 100 possessions.
   - LOWER is BETTER (allowing fewer points = better defense).
   - So we INVERT the normalization: def_score = 100 - normalized_value
   - This way, the best defender gets score 100 and worst gets 0.

3. WEIGHTED OVERALL RATING
   - We combine 3 normalized scores with weights:
     Overall = (Offense × 0.4) + (Defense × 0.4) + (Win% × 0.2)
   - Why 40/40/20? Offense and defense are equally important, with win
     percentage adding context for historical consistency.

4. MATCH PREDICTION (Head-to-Head)
   - To predict who wins a game between Team A vs Team B:
     Step 1: Get each team's season win percentage (e.g., BOS=0.642, GSW=0.481)
     Step 2: Normalize to a head-to-head probability:
             total = 0.642 + 0.481 = 1.123
             BOS chance = 0.642 / 1.123 = 57.2%
             GSW chance = 0.481 / 1.123 = 42.8%
     Step 3: Higher chance = projected winner (BOS wins)
     Step 4: Confidence = |57.2% - 42.8%| = 14.3% gap

==============================================================================
"""

import csv
import json
import os
from collections import defaultdict


# =============================================================================
# STEP 1: MIN-MAX NORMALIZATION FUNCTION
# =============================================================================
# This function takes a raw value and scales it to a 0-100 range.
#
# HOW IT WORKS:
#   - Subtract the minimum value (shifts the range to start at 0)
#   - Divide by the range (max - min) to get a 0-to-1 ratio
#   - Multiply by 100 to get a percentage (0-100 scale)
#
# EDGE CASE: If all teams have the same value (max == min), division by zero
#            would occur, so we return 50 (middle score) as a safe default.
#
# EXAMPLE:
#   normalize(115.0, 110.0, 121.0)
#   = ((115.0 - 110.0) / (121.0 - 110.0)) × 100
#   = (5.0 / 11.0) × 100
#   = 45.45
# =============================================================================
def normalize(value, min_val, max_val):
    """Min-Max Normalization: Scales a value to 0-100 range."""
    if max_val == min_val:
        return 50  # All teams are equal → default to midpoint
    return ((value - min_val) / (max_val - min_val)) * 100


def process_csvs():
    # ==========================================================================
    # STEP 2: CONFIGURATION — File paths & division-to-CSV mapping
    # ==========================================================================
    # Each CSV file was generated by Azure ML AutoML. One per NBA division.
    # The Azure ML model was trained on 2016-2025 NBA season data and
    # predicts the 2025-26 season outcomes.
    # ==========================================================================
    azure_folder = 'c:/Users/Vince/Downloads/NBA-Oracle/csvnba/azure_predictions'
    csv_files = {
        'atlantic': 'atlanticpredictions.csv',
        'central': 'central-division_predictions.csv',
        'northwest': 'northwest_predictions.csv',
        'pacific': 'pacific_predictions.csv'
    }

    # Output JSON structure — this is what the web dashboard reads
    final_data = {
        "meta": {
            "model": "Azure ML Ensemble v2.1",
            "version": "2.1",
            "last_updated": "2026-02-14",
            # These are the seasons used as TRAINING DATA for the ML model
            "dataset_seasons": [
                "2016-17", "2017-18", "2018-19", "2019-20", "2020-21",
                "2021-22", "2022-23", "2023-24", "2024-25", "2025-26"
            ],
            "prediction_target": "2025-26"
        },
        "divisions": {}
    }

    division_teams = defaultdict(list)  # Groups teams by division
    all_teams_data = []                 # Flat list of ALL teams (for global min/max)

    # ==========================================================================
    # STEP 3: READ & PARSE ALL CSV FILES
    # ==========================================================================
    # We loop through each division's CSV file and extract:
    #   - Current season (2025-26) data: The ML predictions for this season
    #   - Historical data: Past seasons for trend analysis
    #
    # Key columns from Azure ML CSVs:
    #   - Season_orig:       The NBA season (e.g., "2025-26")
    #   - Team_orig:         Full team name (e.g., "Boston Celtics")
    #   - Win_Pct_orig:      Team's win percentage (e.g., 0.642 = 64.2%)
    #   - Off_Rating_orig:   Offensive Rating (points scored per 100 possessions)
    #   - Def_Rating_orig:   Defensive Rating (points ALLOWED per 100 possessions)
    #   - 1_predicted_proba: Azure ML's predicted probability of making playoffs
    #   - MadePlayoffs_predicted: Binary prediction (1 = makes playoffs, 0 = no)
    # ==========================================================================
    for div_key, filename in csv_files.items():
        filepath = os.path.join(azure_folder, filename)
        if not os.path.exists(filepath):
            print(f"File not found: {filepath}")
            continue

        with open(filepath, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            rows = list(reader)

            # Determine conference based on division
            # Eastern Conference: Atlantic, Central, Southeast
            # Western Conference: Northwest, Pacific, Southwest
            conf = "Eastern" if div_key in ['atlantic', 'central', 'southeast'] else "Western"

            # Separate current season predictions from historical data
            current_season_rows = [r for r in rows if r['Season_orig'] == '2025-26']
            historical_rows = [r for r in rows if r['Season_orig'] != '2025-26']

            # =====================================================================
            # STEP 3a: Build Historical Data (for trend charts on the dashboard)
            # =====================================================================
            history_by_team = defaultdict(list)
            for h in historical_rows:
                history_by_team[h['Team_orig']].append({
                    "season": h['Season_orig'],
                    "win_pct": float(h.get('Win_Pct_orig', 0)),
                    "off_rating": float(h.get('Off_Rating_orig', 0)),
                    "def_rating": float(h.get('Def_Rating_orig', 0)),
                    "made_playoffs": int(h.get('MadePlayoffs_orig', 0)) == 1
                })

            # =====================================================================
            # STEP 3b: Process Current Season (2025-26) Predictions
            # =====================================================================
            for row in current_season_rows:
                team_name = row['Team_orig']

                # Azure ML gives us a probability (0.0 - 1.0) of making playoffs
                # This is the key ML output: "1_predicted_proba"
                prob_made_playoffs = float(row.get('1_predicted_proba', 0))

                # ============================================================
                # PLAYOFF STATUS CLASSIFICATION
                # ============================================================
                # We classify teams into 3 tiers based on Azure ML probability:
                #   > 0.8 (80%+)   → "clinched"   (Almost certainly in playoffs)
                #   < 0.2 (20%-)   → "eliminated"  (Almost certainly out)
                #   0.2 to 0.8     → "contender"   (Still in the race)
                # ============================================================
                if prob_made_playoffs > 0.8:
                    status = "clinched"
                elif prob_made_playoffs < 0.2:
                    status = "eliminated"
                else:
                    status = "contender"

                # Collect the key stats from the CSV
                stats = {
                    "win_pct": float(row.get('Win_Pct_orig', 0)),
                    "off_rating": float(row.get('Off_Rating_orig', 0)),
                    "def_rating": float(row.get('Def_Rating_orig', 0)),
                    # Net Rating = Offense - Defense
                    # Positive = you score more than you allow (GOOD)
                    # Negative = you allow more than you score (BAD)
                    "net_rating": round(
                        float(row.get('Off_Rating_orig', 0)) - float(row.get('Def_Rating_orig', 0)), 1
                    ),
                    "efficiency_pct": float(row.get('Win_Pct_orig', 0.5)) * 0.8
                }

                team_obj = {
                    "team": team_name,
                    "season": "2025-26",
                    "stats": stats,
                    "playoff_status": status,
                    "historical": sorted(history_by_team[team_name], key=lambda x: x['season']),
                    "raw_prob": prob_made_playoffs  # Keep for sorting, remove later
                }
                division_teams[div_key].append(team_obj)
                all_teams_data.append(team_obj)

    # ==========================================================================
    # STEP 4: CALCULATE GLOBAL MIN/MAX FOR NORMALIZATION
    # ==========================================================================
    # WHY GLOBAL?
    #   We need to compare teams ACROSS all divisions on the same scale.
    #   If we normalized per-division, a "100" in the Atlantic might mean
    #   Off Rating = 120, but "100" in the Pacific might mean 118.
    #   Global normalization ensures a fair, consistent comparison.
    #
    # We find the minimum and maximum values across ALL 20 teams for:
    #   - Offensive Rating (higher = better offense)
    #   - Defensive Rating (lower = better defense)
    #   - Win Percentage (higher = more wins)
    # ==========================================================================
    if not all_teams_data:
        print("No data found!")
        return

    max_off = max(t['stats']['off_rating'] for t in all_teams_data)
    min_off = min(t['stats']['off_rating'] for t in all_teams_data)
    max_def = max(t['stats']['def_rating'] for t in all_teams_data)
    min_def = min(t['stats']['def_rating'] for t in all_teams_data)
    max_win = max(t['stats']['win_pct'] for t in all_teams_data)
    min_win = min(t['stats']['win_pct'] for t in all_teams_data)

    print(f"\n--- Normalization Bounds (Global) ---")
    print(f"Offensive Rating: min={min_off}, max={max_off}")
    print(f"Defensive Rating: min={min_def}, max={max_def}")
    print(f"Win Percentage:   min={min_win}, max={max_win}")
    print(f"-------------------------------------\n")

    # ==========================================================================
    # STEP 5: NORMALIZE SCORES & BUILD FINAL DIVISION DATA
    # ==========================================================================
    for div_key, teams in division_teams.items():
        # Sort teams by Azure ML playoff probability (best first)
        teams.sort(key=lambda x: x['raw_prob'], reverse=True)

        # ======================================================================
        # STEP 5a: Division-Level Analytics
        # ======================================================================
        div_analytics = {
            "strongest_team": teams[0]['team'],
            "weakest_team": teams[-1]['team'],
            "playoff_teams": sum(1 for t in teams if t['playoff_status'] == 'clinched'),
            "average_off_rating": round(sum(t['stats']['off_rating'] for t in teams) / len(teams), 1),
            "average_def_rating": round(sum(t['stats']['def_rating'] for t in teams) / len(teams), 1),
            "average_win_pct": round(sum(t['stats']['win_pct'] for t in teams) / len(teams), 3),
        }

        # Find the best offense and defense in this division
        # Best offense = HIGHEST Off Rating
        # Best defense = LOWEST Def Rating (allows fewest points)
        best_off = max(teams, key=lambda x: x['stats']['off_rating'])
        best_def = min(teams, key=lambda x: x['stats']['def_rating'])
        div_analytics["best_offense"] = best_off['team']
        div_analytics["best_defense"] = best_def['team']

        # ======================================================================
        # STEP 5b: NORMALIZE EACH TEAM'S STATS (0-100 scale)
        # ======================================================================
        # This is the core normalization step. For each team:
        #
        # 1. OFFENSIVE SCORE (Higher raw value = Higher score = Better)
        #    off_score = normalize(off_rating, global_min, global_max)
        #    Example: off_rating=120, min=110, max=121
        #             → ((120 - 110) / (121 - 110)) × 100 = 90.9
        #
        # 2. DEFENSIVE SCORE (Lower raw value = Better, so we INVERT)
        #    def_norm  = normalize(def_rating, global_min, global_max)
        #    def_score = 100 - def_norm
        #    Example: def_rating=108.4, min=108.4, max=119.8
        #             → def_norm = ((108.4 - 108.4) / (119.8 - 108.4)) × 100 = 0.0
        #             → def_score = 100 - 0.0 = 100.0 (best defense!)
        #    Example: def_rating=119.8, min=108.4, max=119.8
        #             → def_norm = ((119.8 - 108.4) / (119.8 - 108.4)) × 100 = 100.0
        #             → def_score = 100 - 100.0 = 0.0 (worst defense!)
        #
        # 3. WIN PERCENTAGE SCORE (Higher = Better)
        #    win_score = normalize(win_pct, global_min, global_max)
        #
        # 4. WEIGHTED OVERALL RATING
        #    overall = (off_score × 0.4) + (def_score × 0.4) + (win_score × 0.2)
        #
        #    The weights mean:
        #      - 40% weight on offense (how well you score)
        #      - 40% weight on defense (how well you prevent scoring)
        #      - 20% weight on win record (overall season success)
        # ======================================================================
        final_teams = []
        for t in teams:
            # --- Offensive Score ---
            # Higher Off Rating = Higher Score (direct normalization)
            off_score = normalize(t['stats']['off_rating'], min_off, max_off)

            # --- Defensive Score ---
            # Lower Def Rating = Better defense, so INVERT the normalization
            # Step A: Normalize normally (low def_rating → low score)
            def_norm = normalize(t['stats']['def_rating'], min_def, max_def)
            # Step B: Invert it (100 - score), so low def_rating → HIGH score
            def_score = 100 - def_norm

            # --- Win Percentage Score ---
            # Higher Win% = Higher Score (direct normalization)
            win_score = normalize(t['stats']['win_pct'], min_win, max_win)

            # --- Weighted Overall Rating ---
            # Combines all three scores with predefined weights
            overall = (off_score * 0.4) + (def_score * 0.4) + (win_score * 0.2)

            # Store the normalized scores in the team object
            t['normalized_scores'] = {
                "offensive_score": round(off_score, 1),
                "defensive_score": round(def_score, 1),
                "win_pct_score": round(win_score, 1),
                "overall_rating": round(overall, 1)
            }

            # Print for debugging/verification
            print(f"  {t['team']:30s} | OFF: {off_score:5.1f} | DEF: {def_score:5.1f} | WIN: {win_score:5.1f} | OVERALL: {overall:5.1f}")

            # Remove temporary helper key (not needed in final JSON)
            del t['raw_prob']
            final_teams.append(t)

        # Build the final division object
        final_data['divisions'][div_key] = {
            "name": f"{div_key.capitalize()} Division",
            "conference": "Eastern" if div_key in ['atlantic', 'central'] else "Western",
            "teams": final_teams,
            "division_analytics": div_analytics
        }

    # ==========================================================================
    # STEP 6: WRITE OUTPUT JSON
    # ==========================================================================
    output_path = 'c:/Users/Vince/Downloads/NBA-Oracle/azure_predictions.json'
    with open(output_path, 'w') as f:
        json.dump(final_data, f, indent=2)
    print(f"\nSuccessfully created {output_path}")


if __name__ == "__main__":
    process_csvs()
